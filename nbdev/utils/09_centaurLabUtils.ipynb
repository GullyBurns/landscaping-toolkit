{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66bffd50-d708-4510-8286-d30a3923bb05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# default_exp centaurLabsUtils\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "929a8609-b050-4b20-b534-df455a3f4677",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# CentaurLab Utility Tools \n",
    "# MAGIC\n",
    "> Tools to upload, download, and analyze data from CentaurLabs using their curation interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b5830e2-0b0d-4e2d-94fa-f21c12373b77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import urllib.request \n",
    "import spacy\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f22c2566-fd31-4eaf-ba8c-f11701d244b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class CentaurLabsUploadUtils: \n",
    "  '''\n",
    "  Tools to provide capabilities to interface dashboard databases with CentaurLabs' curation \n",
    "  systems \n",
    "  \n",
    "  Documentation: https://docs.centaurlabs.com/\n",
    "  \n",
    "  Note - this requires that an appropriate scispacy language model be loaded. \n",
    "  \n",
    "  %pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_lg-0.4.0.tar.gz \n",
    "  \n",
    "  Attributes:\n",
    "    * df: The dataframe being processed - expected columns are (A) ID, (B) title, (C) abstract, (D) year, (E) disease, (F) label. \n",
    "    These can be specified with other class attributes\n",
    "    \n",
    "  '''\n",
    "  def __init__(self, df, id_col='ID_PAPER', title_col='Title', abs_col='Abstract', \n",
    "               year_col='YEAR', dis_col='DISEASE', label_col='LABEL'):\n",
    "    self.df = df\n",
    "    self.id_col = id_col\n",
    "    self.title_col = title_col\n",
    "    self.abs_col = abs_col\n",
    "    self.year_col = year_col\n",
    "    self.dis_col = dis_col\n",
    "    self.label_col = label_col\n",
    "    self.nlp = spacy.load(\"en_core_sci_lg\")\n",
    "    \n",
    "  def fix(self, text):\n",
    "    text = unidecode(str(text))\n",
    "    text = re.sub('\\<', '&lt;', text)\n",
    "    text = re.sub('\\>', '&gt;', text)\n",
    "    return text\n",
    "  \n",
    "  def generate_html_column(self, maxpos, html_col='HTML'):\n",
    "    final_list = []\n",
    "    for i, row in tqdm(self.df.iterrows()):\n",
    "      disease = str(row[self.dis_col])\n",
    "      id = str(row[self.id_col])\n",
    "      title = self.fix(row[self.title_col])\n",
    "      abstract = self.fix(row[self.abs_col])\n",
    "      text = title + '. ' + abstract \n",
    "      doc = self.nlp(text)\n",
    "      if len(doc)>maxpos:\n",
    "        title_doc = self.nlp(title)\n",
    "        title_len = len(title_doc)\n",
    "        pos = doc[len(doc)+len(title_doc)-maxpos].idx\n",
    "        abstract = ' ... ' + text[pos:]\n",
    "      html = '<html>'+\\\n",
    "          '<div style=\"font-size: 20px; color: white; font-family: sans-serif; font-weight: lighter; line-height: 130%;\">'+\\\n",
    "          '<p><b>DISEASE: </b>'+disease+'</p>'+\\\n",
    "          '<p><b>ID: </b>'+id+'</p>'+\\\n",
    "          '<p><b>TITLE: </b>'+title+'</p>'+\\\n",
    "          '<p><b>ABSTRACT: </b>'+abstract+'</p>'+\\\n",
    "          '</div></html>'\n",
    "      final_list.append(html.replace('\\n',' '))\n",
    "    self.df[html_col] = final_list\n",
    "    \n",
    "class CentaurLabsDownmUtils: \n",
    "  '''\n",
    "  Tools to process and evaluate data downloaded from CentaurLabs' curation systems\n",
    "  \n",
    "  Attributes:\n",
    "    * centaur_df: The dataframe downloaded from Centaurlabs. These have a standard format. \n",
    "    * text_df: The dataframe uploaded to Centaurlabs (formatted to hmtl) \n",
    "    \n",
    "  '''\n",
    "  def __init__(self, centaur_df, html_df):\n",
    "    centaur_df = centaur_df.drop(columns=[c for c in df.columns if c not in ['Case ID', 'Origin', 'URL', 'Labeling State', 'Qualified Reads', \n",
    "                                                            'Correct Label', 'Agreement', 'Title', 'Abstract',\n",
    "                                                            'First Choice Answer', 'First Choice Weight',\n",
    "                                                            'Second Choice Answer', 'Second Choice Weight',\n",
    "                                                            'Third Choice Answer', 'Third Choice Weight',\n",
    "                                                            'Fourth Choice Answer', 'Fourth Choice Weight']])\n",
    "    centaur_df = centaur_df.rename(columns = {c:re.sub(' ','_',c) for c in centaur_df.columns})\n",
    "    self.centaur_df = centaur_df[(centaur_df['Agreement'].isnull()==False)]\n",
    "    self.html_df = html_df\n",
    "    \n",
    "  def map_html_to_df(self, df):     \n",
    "    p1 = '<b>TITLE: </b>(.*?)</p>'\n",
    "    p2 = '<b>ABSTRACT: </b>(.*?)</p>'\n",
    "    p3 = '<b>ID: </b>(.*?)</p>'\n",
    "    titles = [re.search(p1, row.html).group(1) for row in df.itertuples()]\n",
    "    abstracts = [re.search(p2, row.html).group(1) for row in df.itertuples()]\n",
    "    ids = [int(re.search(p3, row.html).group(1)) for row in df.itertuples()]\n",
    "    df2 = pd.DataFrame([(i,j,k) for i,j,k in zip(ids, titles, abstracts)], columns=['ID','Title','Abstract'])\n",
    "    return df2\n",
    "  \n",
    "  def compute_thresholded_f1_scores(self):\n",
    "    gold_standard = self.centaur_df[(self.centaur_df['Labeling_State']=='Gold Standard') & (self.centaur_df['Agreement']>=0)].sort_values('Agreement')\n",
    "    categories_to_include = sorted(self.centaur_df['Correct_Label'].unique())\n",
    "    centaur_categories = ['-1', '0', '1', '2']\n",
    "    true_cats = [re.search(\"(\\d) - .*\", x).group(1) for x in gold_standard['Correct_Label'].to_list()]\n",
    "    pred_cats = []\n",
    "    vector_list = []\n",
    "    agreement = gold_standard['Agreement'].to_list()\n",
    "    cols = gold_standard.columns.to_list()\n",
    "    vector_list = []\n",
    "    for row in gold_standard.itertuples():\n",
    "      m = {}\n",
    "      m[row.First_Choice_Answer] = round(row.First_Choice_Weight, 2)\n",
    "      m[row.Second_Choice_Answer] = round(row.Second_Choice_Weight, 2)\n",
    "      m[row.Third_Choice_Answer] = round(row.Third_Choice_Weight, 2)\n",
    "      m[row.Fourth_Choice_Answer] = round(row.Fourth_Choice_Weight, 2)\n",
    "      vector = [m[c] for c in categories_to_include]\n",
    "      vector_list.append(vector)\n",
    "      pred_cats.append(centaur_categories[vector.index(max(vector))])\n",
    "    gold_standard['vector'] = vector_list \n",
    "    gold_standard['predicted'] = pred_cats \n",
    "    gold_standard['Correct_Label'] = true_cats\n",
    "    gold_standard = gold_standard.drop(columns=['First_Choice_Answer', 'First_Choice_Weight', \n",
    "                                                'Second_Choice_Answer', 'Second_Choice_Weight', \n",
    "                                                'Third_Choice_Answer', 'Third_Choice_Weight', \n",
    "                                                'Fourth_Choice_Answer', 'Fourth_Choice_Weight']).fillna('')\n",
    "    f1 = []\n",
    "    for thresh in np.linspace(0,1,100):\n",
    "      i = 0\n",
    "      for j, a in enumerate(agreement):\n",
    "        if a>thresh:\n",
    "          i = j\n",
    "          break\n",
    "      t = true_cats[i:]\n",
    "      p = pred_cats[i:]\n",
    "      f1.append((thresh, len(t)/len(gold_standard), f1_score(t, p, average='micro'), f1_score(t, p, average='macro')))\n",
    "    f1.pop()\n",
    "    f1_df = pd.DataFrame(f1, columns=['agreement', 'Fraction of Data', 'F1_micro', 'F1_macro'])\n",
    "    f1_df.drop(columns=['Fraction of Data']).plot(x='agreement')\n",
    "    f1_df.drop(columns=['F1_micro','F1_macro']).plot(x='agreement')\n",
    "    return f1_df\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "09_centaurLabUtils",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
